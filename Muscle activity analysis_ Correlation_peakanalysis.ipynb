{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import scipy.signal as scisig\n",
    "import matplotlib \n",
    "from scipy.integrate import simps\n",
    "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
    "import scikit_posthocs as spost\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definitions\n",
    "peak_prom = 20\n",
    "smoothed = 'yes'\n",
    "threshold = 30\n",
    "frame_rate = 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_xana_spinning(excel_name,filename_ending,stimulation_times):\n",
    "    data_longform = pd.DataFrame(columns = [\"Filename\",\"Time\",\"Muscle\",\"value\"])\n",
    "    for i in range(len(stimulation_times)):\n",
    "        #print(i)\n",
    "        filename = 'Rawdata_Fiji_Fly'+str(i+1)+filename_ending\n",
    "        #print(filename)\n",
    "        dataframe = pd.read_excel(excel_name,sheet_name=filename,skiprows=0)\n",
    "        #print(dataframe)\n",
    "        levator_act, depressor_act = fluorescence_measure(dataframe)\n",
    "        timepoints = dataframe.Frame-stimulation_times[i]\n",
    "        #print(timepoints)\n",
    "        dataz = {'Time':timepoints,'Levator':levator_act,'Depressor':depressor_act}\n",
    "        dataz = pd.DataFrame(dataz)\n",
    "        dataz[\"Filename\"] = filename\n",
    "        #print(dataz)\n",
    "        data_melted = pd.melt(dataz,id_vars=[\"Filename\",\"Time\"],var_name=\"Muscle\")\n",
    "        #print(data_melted)\n",
    "        data_longform = data_longform.append(data_melted)\n",
    "    return data_longform\n",
    "\n",
    "def fluorescence_measure(dataframe):\n",
    "    \n",
    "    #Define Levator and Depressor mean fluorescences\n",
    "    levator_fluor = dataframe['Mean1']\n",
    "    depressor_fluor = dataframe['Mean2']\n",
    "    frames = dataframe['Frame']\n",
    "\n",
    "    #Find Max and min of fluorescence for both muscles\n",
    "    levator_fmax = max(levator_fluor)\n",
    "    levator_fmin = min(levator_fluor)\n",
    "\n",
    "    depressor_fmax = max(depressor_fluor)\n",
    "    depressor_fmin = min(depressor_fluor)\n",
    "\n",
    "    #Normalizing the fluorescence \n",
    "    #Mean of each frame minus min\n",
    "    levator_fnorm = levator_fluor - levator_fmin\n",
    "    #Maximum minus minimum will give us the highest activity normalized\n",
    "    levator_maxnorm = levator_fmax - levator_fmin\n",
    "\n",
    "    #same for depressor muscle\n",
    "    depressor_fnorm = depressor_fluor - depressor_fmin\n",
    "    depressor_maxnorm = depressor_fmax - depressor_fmin\n",
    "\n",
    "    #Calculate percentage of muscles activity\n",
    "    levator_act = (levator_fnorm*100)/levator_maxnorm\n",
    "    depressor_act = (depressor_fnorm*100)/depressor_maxnorm\n",
    "    \n",
    "    return levator_act, depressor_act\n",
    "\n",
    "#fluorescence_measure(dataframe)\n",
    "\n",
    "def scorrelation_muscle_activity(levator_act,depressor_act,times): #looks at the correlation between muscle activity for only the times after the stimulation\n",
    "    \n",
    "    #select only the timepoints after the stimulation \n",
    "    levator_act = np.array(levator_act)[times >=0]\n",
    "    depressor_act = np.array(depressor_act)[times >= 0]\n",
    "    \n",
    "    #First we need to exclude areas where both muscle activity is null\n",
    "    levator_less5 = np.where(levator_act<20) #Find where levator activity is smaller than 20%\n",
    "    depressor_less5 = np.where (depressor_act <20) #Find where depressor activity is smaller than 20%\n",
    "    timewindow = np.intersect1d(levator_less5, depressor_less5) #Find where both muscles have activity <20%\n",
    "    #use only the selected frames for the correlation analysis\n",
    "    #delete from the data the values in which activity of is below 20 for both of the muscles\n",
    "    levator_select = np.delete(levator_act, timewindow)\n",
    "    depressor_select= np.delete(depressor_act,timewindow)\n",
    "    \n",
    "    #fig,ax = plt.subplots(figsize = [5,5])\n",
    "    #plt.scatter(levator_select,depressor_select)\n",
    "    #print(levator_select)\n",
    "    #print(depressor_select)\n",
    "    \n",
    "    if len(levator_select) <2 or len(depressor_select) <2:\n",
    "        r=np.nan\n",
    "        pvalue =np.nan\n",
    "    else:\n",
    "        r,pvalue = stats.spearmanr(levator_select, depressor_select)\n",
    "    \n",
    "    return r,pvalue\n",
    "\n",
    "def wilcoxonz(data):\n",
    "    wilcoxon_pval = []\n",
    "    wilcoxon_stat = []\n",
    "    for f in list(df):\n",
    "        #print(f)\n",
    "        test = data[f]\n",
    "        #print(test)\n",
    "        stat, pval = stats.wilcoxon(test) #do a wilcoxon test on the spearmans correlation scores\n",
    "        wilcoxon_pval.append(pval)\n",
    "        wilcoxon_stat.append(stat)\n",
    "    return wilcoxon_stat,wilcoxon_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ATR_wstim = import_data_xana_spinning('Fluorescence measures_ATR.xlsx','_Stim',[182,99,155,56,131,50,126,22,153,68,26,27,38])\n",
    "ATR_nostim = import_data_xana_spinning('Fluorescence measures_ATR.xlsx','_No_Stim',[0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "ATR_decap = import_data_xana_spinning('Fluorescence measures_ATR.xlsx','_Decap',[210,106,60,39,34,239,35,144,214,25,132,68,23])\n",
    "NoATR_wstim = import_data_xana_spinning('Fluorescence measures_No ATR.xlsx','_Stim',[38,136,13,10,22,77,124,61,129,171,21])\n",
    "NoATR_decap = import_data_xana_spinning('Fluorescence measures_No ATR.xlsx','_Decap',[69,42,95,87,167,208,271,233,22,80,99,32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATR_wstim[\"Condition\"] = \"ATR_wstim\"\n",
    "ATR_nostim[\"Condition\"] = \"ATR_nostim\"\n",
    "NoATR_wstim[\"Condition\"] = \"NoATR_wstim\"\n",
    "ATR_decap[\"Condition\"] = \"ATR_Decap\"\n",
    "NoATR_decap[\"Condition\"] = \"NoATR_Decap\"\n",
    "\n",
    "all_conditions = ATR_wstim.append(ATR_nostim)\n",
    "all_conditions = all_conditions.append(NoATR_wstim)\n",
    "all_conditions = all_conditions.append(ATR_decap)\n",
    "all_conditions = all_conditions.append(NoATR_decap)\n",
    "\n",
    "print(all_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between levator and depressor muscles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_spearmans_corr(dataz):\n",
    "    all_r = []\n",
    "    all_pval = []\n",
    "    for file in dataz.Filename.unique():\n",
    "        data = dataz.query('Filename == @file')\n",
    "        scorr = scorrelation_muscle_activity(data.query('Muscle == \"Levator\"').value,data.query('Muscle == \"Depressor\"').value,data.query('Muscle == \"Levator\"').Time)\n",
    "        #print(\"spearmans = \",str(scorr))\n",
    "        #fig, ax = plt.subplots() \n",
    "        \n",
    "        #plt.scatter(data.query('Muscle == \"Levator\" and Time>0').value,data.query('Muscle == \"Depressor\" and Time>0').value)\n",
    "        \n",
    "        all_r.append(scorr[0])\n",
    "        all_pval.append(scorr[1])\n",
    "    return all_r,all_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spear_ATR_stim_r,spear_ATR_stim_pval = group_spearmans_corr(ATR_wstim)\n",
    "\n",
    "spear_ATR_nostim_r,spear_ATR_nostim_pval = group_spearmans_corr(ATR_nostim)\n",
    "\n",
    "spear_ATR_decap_r,spear_ATR_decap_pval = group_spearmans_corr(ATR_decap)\n",
    "\n",
    "spear_noATR_stim_r,spear_noATR_stim_pval = group_spearmans_corr(NoATR_wstim)\n",
    "\n",
    "spear_noATR_decap_r,spear_noATR_decap_pval = group_spearmans_corr(NoATR_decap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform numpy into pandas since goups have different dimensions\n",
    "df_ATR_Stim = pd.DataFrame(spear_ATR_stim_r, columns = ['ATR Stim'])\n",
    "df_ATR_NoStim = pd.DataFrame(spear_ATR_nostim_r, columns = ['ATR NoStim'])\n",
    "df_ATR_Decap = pd.DataFrame(spear_ATR_decap_r,columns = ['ATR Decap'])\n",
    "df_NoATR_Stim = pd.DataFrame(spear_noATR_stim_r, columns = ['NoATR Stim'])\n",
    "df_NoATR_Decap = pd.DataFrame(spear_noATR_decap_r, columns = ['NoATR Decap'])\n",
    "\n",
    "\n",
    "#Concatenate all groups into a dataframe with index label\n",
    "df = pd.concat([df_NoATR_Stim, df_ATR_NoStim,df_ATR_Stim,df_NoATR_Decap,df_ATR_Decap ],axis=1)\n",
    "wilk = wilcoxonz(df)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax =sns.boxplot(data=df,palette=\"GnBu_d\")\n",
    "ax =sns.swarmplot(data=df,color='black')\n",
    "ax.set(ylim=(-1, 1.1))\n",
    "sns.despine(offset=10, trim=True)\n",
    "ax.axhline(0, color = 'grey', ls='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Person Correlation Plot.svg')\n",
    "plt.savefig('Pearson correlation plot.png')\n",
    "\n",
    "\n",
    "df_melted = pd.melt(df,var_name = [\"Condition\"])\n",
    "\n",
    "post_dunn = spost.posthoc_dunn(df_melted,group_col=\"Condition\",val_col = \"value\")\n",
    "print(\"Post dunn =\")\n",
    "print(post_dunn)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity of muscle contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binz = 15\n",
    "#\n",
    "#histog_ATR = np.histogram(ATR_wstim.query('Time >= 0').value,bins = binz)\n",
    "#histog_ATR_decap = np.histogram(ATR_decap.query('Time >= 0').value,bins = binz)\n",
    "#\n",
    "##normalised values together\n",
    "#fig, ax = plt.subplots(figsize = [7,4])\n",
    "#ax.bar(histog_ATR[1][:-1],histog_ATR[0]/np.sum(histog_ATR[0]),width = 4,label=\"ATR with stim\")\n",
    "#ax.bar(histog_ATR_decap[1][:-1]+1,histog_ATR_decap[0]/np.sum(histog_ATR_decap[0]),width = 4,label=\"ATR decapitated\")\n",
    "#ax.legend()\n",
    "#\n",
    "#\n",
    "#viol_data = all_conditions.query('Time > 0')\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize = [4,5])\n",
    "#ax =sns.boxplot(x = \"Condition\",y=\"value\",data=viol_data.query('Condition == \"ATR with stim\" or Condition == \"ATR Decap\"'),palette=\"GnBu_d\")\n",
    "##ax =sns.swarmplot(data=df,color='black')\n",
    "##ax.set(ylim=(-1, 1.1))\n",
    "#sns.despine(offset=10, trim=True)\n",
    "##ax.axhline(0, color = 'grey', ls='--')\n",
    "#plt.show()\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize = [4,5])\n",
    "#ax =sns.violinplot(x = \"Condition\",y=\"value\",data=viol_data.query('Condition == \"ATR with stim\" or Condition == \"ATR Decap\"'),palette=[\"#539EBA\",\"#3E5660\"],cut = 0)\n",
    "##ax =sns.swarmplot(data=df,color='black')\n",
    "##ax.set(ylim=(-1, 1.1))\n",
    "#sns.despine(offset=10, trim=True)\n",
    "##ax.axhline(0, color = 'grey', ls='--')\n",
    "#plt.show()\n",
    "#\n",
    "#stat,p_val = stats.mannwhitneyu(viol_data.query('Condition == \"ATR with stim\"').value,viol_data.query('Condition == \"ATR Decap\"').value,alternative = 'two-sided')\n",
    "#print('Mann Whitney U stat = ', str(stat),' p value =',str(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number and size of bouts of muscle activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrations of activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_troughs(data,times,peak_prom = peak_prom,trough_ord = 20,smoothed = 'yes',graph = 'yes',title = \"\",threshold = threshold):\n",
    "    times = np.array(times)\n",
    "    \n",
    "    peaks = scisig.find_peaks(data,height = 0, prominence = peak_prom)\n",
    "    peaks_locs = peaks[0]\n",
    "    peaks_heights = peaks[1][\"peak_heights\"]\n",
    "    if threshold > 0:\n",
    "        locations = peaks_heights > threshold\n",
    "        peaks_locs = peaks_locs[locations]\n",
    "        peaks_heights = peaks_heights[locations]\n",
    "    \n",
    "    troughs = scisig.argrelmin(data.values,order = trough_ord)\n",
    "    scatterz2_height = [data.values[x] for x in troughs[0]]\n",
    "    scatterz = [times[x] for x in peaks_locs]\n",
    "    scatterz2 = [times[x] for x in troughs[0]]\n",
    "    \n",
    "    if smoothed  == 'yes': #can smooth the data with different amounts\n",
    "        dataz = data\n",
    "        dataz = dataz.rolling(2,center = True).mean()\n",
    "        peaks_smooth = scisig.find_peaks(dataz,height = 0, prominence = peak_prom)\n",
    "        peaks_locs_smooth = peaks_smooth[0]\n",
    "        peaks_heights_smooth = peaks_smooth[1][\"peak_heights\"]\n",
    "        \n",
    "        if threshold > 0:\n",
    "            locations_smooth = peaks_heights_smooth > threshold\n",
    "            peaks_locs_smooth = peaks_locs_smooth[locations_smooth]\n",
    "            peaks_heights_smooth = peaks_heights_smooth[locations_smooth]\n",
    "        \n",
    "        troughs_smooth = scisig.argrelmin(dataz.values,order = trough_ord)\n",
    "        scatterz2_height_smooth = [dataz.values[x] for x in troughs_smooth[0]]\n",
    "        scatterz_smooth = [times[x] for x in peaks_locs_smooth]\n",
    "        scatterz2_smooth = [times[x] for x in troughs_smooth[0]]\n",
    "    \n",
    "        \n",
    "    if graph == 'yes':\n",
    "        fig2,ax2 = plt.subplots(figsize=(10,4))\n",
    "        plt.plot(times,data,label = \"raw\",color='k',zorder = 1)\n",
    "        plt.scatter(scatterz,peaks_heights,color='b',s=100,zorder = 2,alpha = 0.7,label = \"Peak raw\")\n",
    "        plt.scatter(scatterz2,scatterz2_height,color = [0.2,0.7,0.7])\n",
    "        if smoothed == 'yes':\n",
    "            plt.plot(times,dataz,label = \"smoothed\",color = [0.5,0,0],zorder = 3)\n",
    "            plt.scatter(scatterz_smooth,peaks_heights_smooth,color=[1,0.4,0.4],s = 80,zorder = 4,alpha = 0.7,label = \"Peak smoothed\")\n",
    "            plt.scatter(scatterz2_smooth,scatterz2_height_smooth,color = [1,0.7,0.7])\n",
    "        \n",
    "        #plt.xlim([0,80])\n",
    "        plt.title(title,fontsize=20)\n",
    "        plt.xlabel(\"Time in s\")\n",
    "        plt.ylabel(\"Normalised fluorescence\")\n",
    "        plt.legend()\n",
    "        \n",
    "    if smoothed == 'yes':\n",
    "        return dataz,peaks_locs_smooth,peaks_heights_smooth\n",
    "    else:\n",
    "        return peaks_locs,peaks_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muscle_analysis(data,thresh,peak_prom=peak_prom,smoothed='yes',graphs = 'no'): #threshold is below which there are no peaks\n",
    "    integrations_lev = []\n",
    "    integrations_dep = []\n",
    "    peakheights = []\n",
    "    peaklocs = []\n",
    "    threshold = thresh #threshold below which we don't consider it a muscle contraction\n",
    "    for g in data.Filename.unique():\n",
    "        #print(data.query('Muscle == \"Levator\" and Filename == @g'))\n",
    "        test_peaks_lev = peaks_troughs(data.query('Muscle == \"Levator\" and Filename == @g').value,data.query('Muscle == \"Levator\" and Filename == @g').Time,smoothed = smoothed,peak_prom = peak_prom,threshold = threshold,title = g+\" Levator\",graph=graphs)\n",
    "        #print(test_peaks_lev)\n",
    "        int_lev = simps(np.array(data.query('Muscle == \"Levator\" and Filename == @g').value), np.array(data.query('Muscle == \"Levator\" and Filename == @g').Time))\n",
    "        if test_peaks_lev[1].shape[0] > 0:\n",
    "            integrations_lev.append(int_lev/test_peaks_lev[1].shape[0])\n",
    "        else:\n",
    "            integrations_lev.append(np.nan)\n",
    "        for h,i in enumerate(test_peaks_lev[2]):\n",
    "            peakheights.append(i)\n",
    "            #peaklocs.append(test_peaks_lev[1][h])\n",
    "            #print(peaklocs)\n",
    "            \n",
    "            ## NOT FINISHED; NOT GOOD HERE FOR LOCATIONS\n",
    "#\n",
    "        #print(\"Total area under curve = \",str(int_lev))\n",
    "        #print(\"Average area under each peak = \",str(int_lev/test_peaks_lev[1].shape[0]))\n",
    "        #print(\"\")\n",
    "#        \n",
    "        test_peaks_dep = peaks_troughs(data.query('Muscle == \"Depressor\" and Filename == @g').value,data.query('Muscle == \"Depressor\" and Filename == @g').Time,smoothed = smoothed,peak_prom = peak_prom,threshold = threshold,title = g+\" Depressor\",graph=graphs)\n",
    "        int_dep = simps(np.array(data.query('Muscle == \"Depressor\" and Filename == @g').value), np.array(data.query('Muscle == \"Depressor\" and Filename == @g').Time))\n",
    "        if test_peaks_dep[1].shape[0] > 0:\n",
    "            integrations_dep.append(int_dep/test_peaks_dep[1].shape[0])\n",
    "        else:\n",
    "            integrations_dep.append(np.nan)\n",
    "        \n",
    "        #intergrations_dep.append(int_dep/test_peaks_dep[1].shape[0])\n",
    "        for i in test_peaks_dep[2]:\n",
    "            peakheights.append(i)\n",
    "#            peaklocs.append(i)\n",
    "#        #print(\"Total area under curve = \",str(int_dep))\n",
    "#        #print(\"Average area under each peak = \",str(int_dep/test_peaks_dep[1].shape[0]))\n",
    "#        #print(\"\")\n",
    "#\n",
    "    \n",
    "    #print(integrations_lev)\n",
    "    \n",
    "    #print(peakheights)\n",
    "    return integrations_lev,integrations_dep,peakheights#,peaklocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peak_heights = pd.DataFrame(columns=[\"Condition\",\"Height\"])\n",
    "peak_integrations = pd.DataFrame(columns=[\"Condition\",\"Muscle\",\"Area\"])\n",
    "#only for post stimulation conditions\n",
    "for each in all_conditions.Condition.unique():\n",
    "    print(each)\n",
    "    integration_levator,integration_depressor,peakheight = muscle_analysis(all_conditions.query('Condition == @each and Time >= 0'),threshold,graphs = 'no')\n",
    "    \n",
    "    integrat_lev = pd.DataFrame(integration_levator,columns = [\"Area\"])\n",
    "    integrat_lev[\"Condition\"] = each\n",
    "    integrat_lev[\"Muscle\"] = \"Levator\"\n",
    "    \n",
    "    integrat_dep = pd.DataFrame(integration_depressor,columns = [\"Area\"])\n",
    "    integrat_dep[\"Condition\"] = each\n",
    "    integrat_dep[\"Muscle\"] = \"Depressor\"\n",
    "    \n",
    "    peak_integrations = pd.concat([peak_integrations,integrat_lev,integrat_dep])\n",
    "    #print(peak_integrations)\n",
    "    \n",
    "    peakheight = pd.DataFrame(peakheight,columns = [\"Height\"])\n",
    "    peakheight[\"Condition\"] = each\n",
    "    peak_heights = pd.concat([peak_heights,peakheight])\n",
    "print(peak_heights)\n",
    "print(peak_integrations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = spost.posthoc_dunn(peak_integrations,group_col=\"Condition\",val_col = \"Area\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = [10,6])\n",
    "ax =sns.violinplot(x = \"Condition\",y=\"Area\",data=peak_integrations,palette=\"GnBu_d\")#,cut = 0)\n",
    "ax =sns.swarmplot(x = \"Condition\",y=\"Area\",data=peak_integrations,color='k',s=5)\n",
    "\n",
    "plt.ylabel(\"Normalised fluorescence\",fontsize = 15)\n",
    "plt.savefig('Peak integrations viol.svg')\n",
    "plt.savefig('Peak integrations viol.png')\n",
    "\n",
    "\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = spost.posthoc_dunn(peak_heights,group_col=\"Condition\",val_col = \"Height\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = [10,6])\n",
    "ax =sns.violinplot(x = \"Condition\",y=\"Height\",data=peak_heights,palette=\"GnBu_d\",cut = 0,order = [\"NoATR_wstim\",\"ATR_nostim\",\"ATR_wstim\",\"NoATR_Decap\",\"ATR_Decap\"])\n",
    "#ax =sns.swarmplot(x = \"Condition\",y=\"Height\",data=peak_heights,color='k',s=3,order = [\"NoATR_wstim\",\"ATR_nostim\",\"ATR_wstim\",\"NoATR_Decap\",\"ATR_Decap\"])\n",
    "\n",
    "plt.ylabel(\"Normalised fluorescence\",fontsize = 15)\n",
    "plt.savefig('Peak heights Plot no points.svg')\n",
    "#plt.savefig('Peak heights Plot.png')\n",
    "\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binz = np.linspace(30,100,12)\n",
    "fig, ax = plt.subplots(figsize = [10,5])\n",
    "for each in peak_heights.Condition.unique():\n",
    "    histog_heights = np.histogram(peak_heights.query('Condition == @each').Height,bins = binz)\n",
    "    #print(histog_heights)\n",
    "    plt.plot(histog_heights[1][:-1],histog_heights[0]/np.sum(histog_heights[0]),label=each,linewidth=5)#,palette=\"GnBu_d\")\n",
    "    plt.bar(histog_heights[1][:-1],histog_heights[0]/np.sum(histog_heights[0]),width=5,alpha=0.2)#,palette=\"GnBu_d\")\n",
    "    #ax.bar(histog_ATR_decap_peakheights[1][:-1]+1,histog_ATR_decap_peakheights[0]/np.sum(histog_ATR_decap_peakheights[0]),width = wid,label=\"ATR decapitated\",color=[\"#3E5660\"])\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"Normalised peak height\",fontsize = 12)\n",
    "    plt.ylabel(\"Proportion\",fontsize = 12)\n",
    "plt.savefig('Peak heights histogram all.svg')\n",
    "plt.savefig('Peak heights histogram all.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 20 #number of fluorescence points to go down to define the start of the peak\n",
    "\n",
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "def muscle_peak_width(data,thresh,peak_prom=peak_prom,smoothed='yes',graphs = 'no',condition = \"\"): #threshold is below which there are no peaks\n",
    "    widths_lev = []\n",
    "    widths_dep = []\n",
    "    threshold = thresh #threshold below which we don't consider it a muscle contraction\n",
    "    print(\"levator\")\n",
    "    fig, ax = plt.subplots(len(data.Filename.unique()),1,figsize = [6,18])\n",
    "    print(\"depressor\")\n",
    "    fig2, ax2 = plt.subplots(len(data.Filename.unique()),1,figsize = [6,18])\n",
    "    \n",
    "    for h,g in enumerate(data.Filename.unique()):\n",
    "        test_peaks_lev = peaks_troughs(data.query('Muscle == \"Levator\" and Filename == @g').value,data.query('Muscle == \"Levator\" and Filename == @g').Time,smoothed = smoothed,peak_prom = peak_prom,threshold = threshold,title = g+\" Levator\",graph=graphs)\n",
    "        #print(test_peaks_lev[0])\n",
    "        ax[h].plot(np.arange(test_peaks_lev[0].shape[0])*frame_rate,test_peaks_lev[0])\n",
    "        ax[h].scatter(0,0,s=0)\n",
    "        for j, peak in enumerate(test_peaks_lev[1]):\n",
    "            height_thresh = test_peaks_lev[2][j]-cut_off\n",
    "            thresh_crossings = np.where(test_peaks_lev[0] > height_thresh)\n",
    "            consecutives = consecutive(thresh_crossings[0])\n",
    "\n",
    "            for each in consecutives:\n",
    "                if peak in each:\n",
    "                    ax[h].scatter(peak*frame_rate,test_peaks_lev[2][j])\n",
    "                    ax[h].plot(each*frame_rate,np.repeat(height_thresh,len(each)))#\n",
    "                    widths_lev.append(len(each)*frame_rate)\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_peaks_dep = peaks_troughs(data.query('Muscle == \"Depressor\" and Filename == @g').value,data.query('Muscle == \"Depressor\" and Filename == @g').Time,smoothed = smoothed,peak_prom = peak_prom,threshold = threshold,title = g+\" Depressor\",graph=graphs)\n",
    "        ax2[h].plot(np.arange(test_peaks_dep[0].shape[0])*frame_rate,test_peaks_dep[0])\n",
    "        ax2[h].scatter(0,0,s=0)\n",
    "        \n",
    "        for j, peak in enumerate(test_peaks_dep[1]):\n",
    "            height_thresh = test_peaks_dep[2][j]-cut_off\n",
    "            thresh_crossings = np.where(test_peaks_dep[0] > height_thresh)\n",
    "            consecutives = consecutive(thresh_crossings[0])\n",
    "\n",
    "            for each in consecutives:\n",
    "                if peak in each:\n",
    "                    ax2[h].scatter(peak*frame_rate,test_peaks_dep[2][j])\n",
    "                    ax2[h].plot(each*frame_rate,np.repeat(height_thresh,len(each)))#\n",
    "                    widths_dep.append(len(each)*frame_rate)\n",
    "        ax[h].set_ylim([0,105])\n",
    "        ax2[h].set_ylim([0,105])\n",
    "    fig.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "    \n",
    "    fig.savefig(condition+\" levator.png\")\n",
    "    fig2.savefig(condition+\" depressor.png\")\n",
    "    fig.savefig(condition+\" levator.svg\")\n",
    "    fig2.savefig(condition+\" depressor.svg\")\n",
    "    \n",
    "    output = pd.DataFrame(widths_lev,columns = [\"Widths\"])\n",
    "    output[\"Muscle\"] = \"Levator\"\n",
    "    output[\"Condition\"] = condition\n",
    "    \n",
    "    ext = pd.DataFrame(widths_dep,columns = [\"Widths\"])\n",
    "    ext[\"Muscle\"] = \"Depressor\"\n",
    "    ext[\"Condition\"] = condition\n",
    "    \n",
    "    output = pd.concat([output,ext])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_widths2 = pd.DataFrame(columns = [\"Widths\",\"Muscle\",\"Condition\"])\n",
    "for each in all_conditions.Condition.unique():\n",
    "    widths = muscle_peak_width(all_conditions.query(\"Condition == @each and Time >= 0\"),threshold,graphs='no',condition = each)\n",
    "    all_widths2 = pd.concat([all_widths2,widths],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIDTHS ONLY FOR POST STIM\n",
    "\n",
    "widths_ATRstim = muscle_peak_width(ATR_wstim.query('Time >= 0'),threshold,graphs='no',condition = \"ATR_wstim\")\n",
    "print(widths_ATRstim)\n",
    "\n",
    "widths_ATRdecap = muscle_peak_width(ATR_decap.query('Time >= 0'),threshold,graphs='no',condition = \"ATR_Decap\")\n",
    "print(widths_ATRdecap)\n",
    "\n",
    "widths_ATRnostim = muscle_peak_width(ATR_nostim.query('Time >= 0'),threshold,graphs='no',condition = \"ATR_nostim\")\n",
    "print(widths_ATRnostim)\n",
    "\n",
    "widths_No_ATR_wstim = muscle_peak_width(NoATR_wstim.query('Time >= 0'),threshold,graphs='no',condition = \"NoATR_wstim\")\n",
    "print(widths_No_ATR_wstim)\n",
    "\n",
    "widths_No_ATRdecap = muscle_peak_width(NoATR_decap.query('Time >= 0'),threshold,graphs='no',condition = \"NoATR_Decap\")\n",
    "print(widths_No_ATRdecap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_widths = pd.concat([widths_ATRstim,widths_ATRdecap])\n",
    "all_widths = pd.concat([all_widths,widths_ATRnostim])\n",
    "all_widths = pd.concat([all_widths,widths_No_ATR_wstim])\n",
    "all_widths = pd.concat([all_widths,widths_No_ATRdecap])\n",
    "\n",
    "pval = spost.posthoc_dunn(all_widths,group_col=\"Condition\",val_col = \"Widths\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10,6])\n",
    "sns.swarmplot(x=\"Condition\",y=\"Widths\",data=all_widths,color='k',size=2,order = [\"NoATR_wstim\",\"ATR_nostim\",\"ATR_wstim\",\"NoATR_Decap\",\"ATR_Decap\"])\n",
    "sns.violinplot(x=\"Condition\",y=\"Widths\",data=all_widths,cut=0,palette = \"GnBu_d\",order = [\"NoATR_wstim\",\"ATR_nostim\",\"ATR_wstim\",\"NoATR_Decap\",\"ATR_Decap\"])\n",
    "#plt.text(0.02, 0.03, \"p = \" + str(np.round(pval,8)), fontsize=12, transform=plt.gcf().transFigure)\n",
    "#plt.savefig('Peak widths Plot.png')\n",
    "plt.ylabel(\"Peak width in s\",fontsize=15)\n",
    "plt.savefig('Peak widths Plot.svg')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#sns.swarmplot(x=\"Condition\",y=\"Widths\",data=all_widths,color='k',size=3)\n",
    "sns.boxplot(x=\"Condition\",y=\"Widths\",data=all_widths,palette = \"GnBu_d\")\n",
    "plt.savefig('Peak widths Box.png')\n",
    "print(pval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
